# Codenames With RL+Word Embedding Agents

## by Adam von Arnim and Leon Zha

A simple terminal-interfaced Codenames recreation. There are four roles consisting of a codemaster and guesser for both red team and blue team. You may specify any of the four roles to be played by agents rather than humans for both training and actual play time. Agents are based on a combination of reinforcement learning and word embedding methods. Base code is modified from https://github.com/maurock/snake-ga/blob/master/DQN.py, which is a DQN originally used to play the game Snake.
<br> </br>
How to run:

- Requirements: We used Python 3.10.0, although slightly earlier versions should work as well. All packages required are listed on the top of each .py file, although some noteable ones are pandas, numpy, gensim, torch, argparse, and scipy.

- Directory setup: AgentCodemaster.py, AgentGuesser.py, bcolors.py, Codemaster.py, Game.py, Guesser.py, HumanCodemaster.py, HumanGuesser.py, runner.py, and wordbank.txt should be in the same directory. Additionally, there should be two empty folders, 'metrics' and 'weights', also in the same directory as the other files.

- Commands to start up the game:

  - The base command to use (in the terminal while in the same directory as the files above) is `python ./runner.py`. This command will instantiate all roles with agents and train for 10,000 games. A variety of optional flags are available to help customize one's desired settings:

    - `--codemasterRed`/`codemasterBlue`/`guesserRed`/`guesserBlue`: including any of these flags will instead allow a human to assume the respective role. These flags may be included in any combination
    - `--red_codemaster_weights`/`--blue_codemaster_weights`/`--red_guesser_weights`/`--blue_guesser_weights`: these flags must be followed by the path to a file where the weights for the respective roles are stored. These will point to files generated by default during training in the 'weights' folder by default. Only use in conjunction with the `--test` flag.
    - `--debug_mode`: including this flag prints out debugging statements to the terminal
    - `--no_display`: including this flag suppresses all printed out board related displays
    - `--no_print`: including this flag suppressess all printing to the terminal. Should be used during training time to speed up training so board displays and other outputs won't be printed out since printing is slow.
    - `--test`: including this flag indicates that the users would like to play an actual game of Codenames, not to train the model.
    - `--output_dir`: this flag must be followed by the path to where output metrics should be stored. Defaults to the 'metrics' folder.

Additional parameters such as epsiolon_decay_linear, learning_rate, and episodes (which specifies how many episodes are run) can be found in the `runner.py` file's `define_parameters()` function.
